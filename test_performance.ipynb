{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5634df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.textclf_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce59ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: cpu, dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = torch.float16 if device == 'cuda' else torch.float32\n",
    "print(f\"Używane urządzenie: {device}, dtype: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defa859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02227b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ustawienia Globalne\n",
    "EMBED_DIM = 128\n",
    "ATTN_EMBED_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "BATCH_SIZE = 1\n",
    "NUM_WARMUP = 10\n",
    "NUM_RUNS = 10\n",
    "HEAD_DIM = EMBED_DIM // NUM_HEADS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "favor = AttentionBlock(\n",
    "    embedding_dim=EMBED_DIM, num_heads=NUM_HEADS, projection_bias=True,\n",
    "    attn_dropout=0.0, out_dropout=0.0, attention_kind='favor',\n",
    "    attention_params={'nb_features': 64, 'redraw_interval': 0, 'ortho_features': True, 'phi': 'exp', 'stabilize': True, 'eps': 1.0e-6}\n",
    ").to(device).to(dtype).eval()\n",
    "\n",
    "lsh = AttentionBlock(\n",
    "    embedding_dim=EMBED_DIM, num_heads=NUM_HEADS, projection_bias=True,\n",
    "    attn_dropout=0.0, out_dropout=0.0, attention_kind='lsh',\n",
    "    attention_params={'num_hashes': 2, 'chunk_size': 64, 'mask_within_chunks': True}\n",
    ").to(device).to(dtype).eval()\n",
    "\n",
    "flash = nn.MultiheadAttention(embed_dim=EMBED_DIM, num_heads=NUM_HEADS, dropout=0.0,\n",
    "                            bias=True, batch_first=True, device=device).to(dtype).eval()\n",
    "\n",
    "mha = AttentionBlock(\n",
    "    embedding_dim=EMBED_DIM,  num_heads=NUM_HEADS, projection_bias=True,\n",
    "    attn_dropout=0.0, out_dropout=0.0, attention_kind='mha',\n",
    "    attention_params={}\n",
    ").to(device).to(dtype).eval()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. FUNKCJE POMOCNICZE\n",
    "# ==============================================================================\n",
    "\n",
    "def rand_inputs(seq_len, device, dtype):\n",
    "    x = torch.randn(BATCH_SIZE, seq_len, EMBED_DIM, device=device, dtype=dtype)\n",
    "    mask = torch.rand(BATCH_SIZE, seq_len, device=device) < 0.1\n",
    "    return x, mask\n",
    "\n",
    "\n",
    "def time_run(func, x, key_padding_mask, num_runs, num_warmup):\n",
    "    \"\"\"Przeprowadza rozgrzewkę i mierzy czas uśredniony (ms).\"\"\"\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # WARMUP\n",
    "    for _ in range(num_warmup):\n",
    "        _ = func(x, key_padding_mask)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    # POMIAR\n",
    "    if device == 'cuda':\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        for _ in range(num_runs):\n",
    "            _ = func(x, key_padding_mask)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        total_time_ms = start_event.elapsed_time(end_event)\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_runs):\n",
    "            _ = func(x, key_padding_mask)\n",
    "        total_time_ms = (time.time() - start_time) * 1000\n",
    "        print(total_time_ms)\n",
    "\n",
    "    \n",
    "\n",
    "    return total_time_ms / num_runs\n",
    "\n",
    "\n",
    "\n",
    "SEQ_LEN_LIST = [128, 256, 512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "results = {\n",
    "    \"FAVOR+ (Twoja Impl.)\": [],\n",
    "    \"LSH Attn (Twoja Impl.)\": [],\n",
    "    \"SDPA (Native - Flash)\": [],\n",
    "    \"SDPA (Native - Non Flash)\": [],\n",
    "    \"SDPA (Ours)\": [],\n",
    "}\n",
    "\n",
    "implementations = {\n",
    "    \"FAVOR+ (Twoja Impl.)\": lambda x, kpm: favor(x, key_padding_mask=kpm),\n",
    "    \"LSH Attn (Twoja Impl.)\": lambda x, kpm: lsh(x, key_padding_mask=kpm),\n",
    "    \"SDPA (Native - Flash)\": lambda x, kpm: flash(x, x, x, need_weights=False,\n",
    "                            key_padding_mask=kpm, average_attn_weights=False),\n",
    "    \"SDPA (Native - Non Flash)\": lambda x, kpm: flash(x, x, x, need_weights=True,\n",
    "                            key_padding_mask=kpm, average_attn_weights=False),\n",
    "    \"SDPA (Ours)\": lambda x, kpm: mha(x, key_padding_mask=kpm),\n",
    "}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seq_len in SEQ_LEN_LIST:\n",
    "        print(f\"Testowanie N = {seq_len}...\")\n",
    "\n",
    "        x, kpm = rand_inputs(seq_len, device=device, dtype=dtype)\n",
    "\n",
    "        for name, func in implementations.items():\n",
    "\n",
    "            avg_time = time_run(func, x, kpm, NUM_RUNS, NUM_WARMUP)\n",
    "\n",
    "            results[name].append(avg_time)\n",
    "            print(f\"  {name:<30}: {avg_time:.4f} ms\")\n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"GPU cache has been emptied.\")\n",
    "        else:\n",
    "            print(\"CUDA is not available. No GPU cache to empty.\")\n",
    "\n",
    "print(\"\\n--- Zakończono pomiary ---\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, times in results.items():\n",
    "    valid_times = [times[i] for i, x in enumerate(times) if not np.isnan(x)]\n",
    "    valid_seq_lens = [SEQ_LEN_LIST[i] for i, x in enumerate(times) if not np.isnan(x)]\n",
    "\n",
    "    # Dodanie stylów dla lepszej czytelności\n",
    "    if \"FAVOR\" in name:\n",
    "        style = {'color': 'blue', 'linestyle': '-', 'marker': 'o'}\n",
    "    elif \"LSH\" in name:\n",
    "        style = {'color': 'green', 'linestyle': '--', 'marker': 's'}\n",
    "    elif \"SDPA\" in name:\n",
    "        style = {'color': 'red', 'linestyle': '-', 'marker': '^'}\n",
    "    else:\n",
    "        style = {'color': 'orange', 'linestyle': ':', 'marker': 'D'}\n",
    "\n",
    "    plt.plot(valid_seq_lens, valid_times, **style, label=name)\n",
    "\n",
    "\n",
    "plt.title(f'Porównanie Czasu Wykonania 4 Implementacji Uwagi (Warmup={NUM_WARMUP}, Runs={NUM_RUNS})', fontsize=16)\n",
    "plt.xlabel('Długość Sekwencji (N)', fontsize=14)\n",
    "plt.ylabel(f'Czas Wykonania (ms)', fontsize=14)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend(fontsize=12, loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
