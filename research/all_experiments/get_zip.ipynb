{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_utils import *\n",
    "import pandas as pd \n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import zipfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3006a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"praca-inzynierska\"\n",
    "project = \"final-experiments\" \n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_runtime = 0\n",
    "for run in runs:\n",
    "    runtime = json.loads(run.summary._json_dict).get(\"_runtime\")\n",
    "    if runtime is not None:\n",
    "        sum_runtime += float(runtime)\n",
    "print(f\"Total runtime (s): {sum_runtime}\")\n",
    "print(f\"Total runtime (h): {sum_runtime/3600}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e239c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, zip_name):\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                full_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(full_path, folder_path)\n",
    "                zipf.write(full_path, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_max_in_step = [\"train/gpu_mem_peak_mb\"]\n",
    "metrics_ignore = [\"train/gpu_mem_peak_mb\",\"train/update_skipped\", \"train/is_update_step\",\"train/accum_step\",\n",
    "                  \"train/lr\",\"train/loss\",\"train/grad_norm\"]\n",
    "\n",
    "def save_run_history_wide_csv_and_max_txt(run, base_dir):\n",
    "    run_dir_name = f\"{run.name}_{run.id}\"\n",
    "    run_dir = os.path.join(base_dir, run_dir_name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    history = run.history(samples=100000)\n",
    "    metric_columns = [c for c in history.columns if not c.startswith(\"_\") and c not in metrics_ignore]\n",
    "\n",
    "    if metric_columns:\n",
    "        wide_df = history[[\"_step\", \"_runtime\"] + metric_columns].copy()\n",
    "\n",
    "        wide_df = wide_df.dropna(subset=metric_columns, how=\"all\")\n",
    "\n",
    "        csv_path = os.path.join(run_dir, \"history_all_metrics.csv.gz\")\n",
    "        wide_df.to_csv(csv_path, index=False, na_rep='', compression='gzip')\n",
    "        print(f\"Saved wide CSV (gzip) for run {run.name} ({run.id})\")\n",
    "    else:\n",
    "        print(f\"No metrics to save for run {run.name} ({run.id})\")\n",
    "\n",
    "    for m in metrics_max_in_step:\n",
    "        txt_path = os.path.join(run_dir, f\"gpu_mem_and_runtime.txt\")\n",
    "        if m in history.columns:\n",
    "            max_val = history[m].max(skipna=True)\n",
    "        else:\n",
    "            max_val = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            runtime = json.loads(run.summary._json_dict).get(\"_runtime\")\n",
    "            if isinstance(runtime, str):\n",
    "                runtime = float(runtime)\n",
    "        except Exception:\n",
    "            runtime = \"N/A\"\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"peak_gpu_mem_mb: {max_val}\\n\")\n",
    "            f.write(f\"runtime_s: {runtime}\\n\")\n",
    "\n",
    "    try:\n",
    "        config_file = run.file(\"config.yaml\")\n",
    "        config_file.download(root=run_dir, replace=True)\n",
    "    except Exception:\n",
    "        print(f\"config.yaml not found for run {run.name} ({run.id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ea2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    save_run_history_wide_csv_and_max_txt(run, './experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e53e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_folder('./experiments', 'experiments.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./experiments/E1_pretraining_wikipedia_bertsmall_mha_hd228t3k/history_all_metrics.csv.gz\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# df['test/accuracy'].loc[~df['test/accuracy'].isna()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
